{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand forecasting based on weather and weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:20.010699Z",
     "start_time": "2018-12-09T12:07:19.528396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load\n",
    "from Preprocessing import *\n",
    "\n",
    "Datapath = \"../Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting\n",
    "I use the pickle files that have already been preprocessed \"Assignment 4 ETL.ipynb\" and the fitted model from \"Assignment 4 Weather prediction.ipynb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:20.287687Z",
     "start_time": "2018-12-09T12:07:20.279976Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(Datapath+\"df_train.p\")\n",
    "df_test = pd.read_pickle(Datapath+\"df_test.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T10:15:51.836123Z",
     "start_time": "2018-12-08T10:15:51.807380Z"
    }
   },
   "source": [
    "# Preprocessing\n",
    "The goal is to predict today's and tomorrow's demand based on the weather prediction of today and tomorrow. That means our predictive model requires 4 input vectors:\n",
    "\n",
    " 1. Predicted Temp for today\n",
    " 2. Predicted Rainfall for today\n",
    " 3. Predicted Temp for tomorrow\n",
    " 4. Predicted Rainfall for tomorrow\n",
    " \n",
    "And one output value:\n",
    " \n",
    " The predicted demand.\n",
    " \n",
    "I prepare input vectors X and output values y that reflect these requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:22.507448Z",
     "start_time": "2018-12-09T12:07:22.482677Z"
    }
   },
   "outputs": [],
   "source": [
    "vals_train = df_train[['Temp', 'Rainfall']].values\n",
    "X_train = np.array([list(vals_train[i]) + list(vals_train[i+1]) for i in range(len(vals_train)-1)])\n",
    "# We can not predict for the final day as we do not have the weather prediction for the day after.\n",
    "y_train = np.array(df_train['Demand'].values)[:-1]\n",
    "\n",
    "vals_test = df_test[['Temp', 'Rainfall']].values\n",
    "X_test = np.array([list(vals_test[i]) + list(vals_test[i+1]) for i in range(len(vals_test)-1)])\n",
    "# We can not predict for the final day as we do not have the weather prediction for the day after.\n",
    "y_test = np.array(df_test['Demand'].values)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting without weekday\n",
    "## Comparing Models\n",
    "First we look at a couple of models without parameter tuning (because parameter tuning can be quite expensive in time). Initially   only weather data is taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some quick testing on Random forests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T10:41:11.519171Z",
     "start_time": "2018-12-09T10:41:11.253462Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T11:32:16.790641Z",
     "start_time": "2018-12-08T11:32:16.786829Z"
    }
   },
   "source": [
    "Linear regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T10:41:11.560352Z",
     "start_time": "2018-12-09T10:41:11.520982Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T10:41:11.659988Z",
     "start_time": "2018-12-09T10:41:11.562212Z"
    }
   },
   "outputs": [],
   "source": [
    "log = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zooming in on Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a random forest performs best, this is actually quite common so I'll do a gridsearch in order to tune the hyperparemters. We check a variety of parameters and use 5-fold validation on the combined data set from 2014 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T10:41:11.664367Z",
     "start_time": "2018-12-09T10:41:11.661442Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cv = np.concatenate((X_train, X_test))\n",
    "y_cv = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning!!! The next cell (gridsearch) takes almost 40 minutes to execute.\n",
    "It finds the best parameters (from a grid of options) and has an attribute called \"best_estimator_\" that is precisely the model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.106461Z",
     "start_time": "2018-12-09T10:41:11.665882Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators' : list(range(5, 101, 5)), 'min_samples_split' : list(range(2, 10)), \n",
    "              'min_samples_leaf' : list(range(2, 10))}\n",
    "m = RFR(n_jobs=-1)\n",
    "clf = GridSearchCV(m, parameters, cv=5)\n",
    "clf.fit(X_cv, y_cv)\n",
    "m = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is given a short description of the model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.121291Z",
     "start_time": "2018-12-09T11:20:11.110717Z"
    }
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.131535Z",
     "start_time": "2018-12-09T11:20:11.125283Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is dumped so it can be used later without doing the expensive gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.143626Z",
     "start_time": "2018-12-09T11:20:11.133872Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(m, Datapath+\"optimal_m_no_weekday.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.150352Z",
     "start_time": "2018-12-09T11:20:11.145172Z"
    }
   },
   "outputs": [],
   "source": [
    "m =  load(Datapath+\"optimal_m_no_weekday.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.368600Z",
     "start_time": "2018-12-09T11:20:11.151822Z"
    }
   },
   "outputs": [],
   "source": [
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model performs with an R2 of about 0.68 which is not great but definitely not bad either.\n",
    "\n",
    "Let's save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T11:20:11.382013Z",
     "start_time": "2018-12-09T11:20:11.371339Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(m, Datapath+\"fitted_m_no_weekday.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with weekday\n",
    "## Comparing Models\n",
    "First we look at a couple of models without parameter tuning (because parameter tuning can be quite expensive in time). This time, we also take weekday data into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:28.480362Z",
     "start_time": "2018-12-09T12:07:28.476995Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.c_[X_train, df_train['Weekday'].values[:-1]]\n",
    "X_test = np.c_[X_test, df_test['Weekday'].values[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T11:32:16.790641Z",
     "start_time": "2018-12-08T11:32:16.786829Z"
    }
   },
   "source": [
    "Linear regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:29.013094Z",
     "start_time": "2018-12-09T12:07:28.979261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4136174145402205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:38.223733Z",
     "start_time": "2018-12-09T12:07:38.119544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40934065934065933"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Regression, allows for the use of categorical data such as weekdays, so we can translate this to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:48.126607Z",
     "start_time": "2018-12-09T12:07:47.831050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7356669308964106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zooming in on Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a random forest performs best, this is actually quite common so I'll do a gridsearch in order to tune the hyperparemters. We check a variety of parameters and use 5-fold validation on the combined data set from 2014 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:07:53.431867Z",
     "start_time": "2018-12-09T12:07:53.428757Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cv = np.concatenate((X_train, X_test))\n",
    "y_cv = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning!!! The next cell (gridsearch) takes almost 40 minutes to execute.\n",
    "It finds the best parameters (from a grid of options) and has an attribute called \"best_estimator_\" that is precisely the model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:46:43.848324Z",
     "start_time": "2018-12-09T12:07:55.026816Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators' : list(range(5, 101, 5)), 'min_samples_split' : list(range(2, 10)), \n",
    "              'min_samples_leaf' : list(range(2, 10))}\n",
    "m = RFR(n_jobs=-1)\n",
    "clf = GridSearchCV(m, parameters, cv=5)\n",
    "clf.fit(X_cv, y_cv)\n",
    "m = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is given a short description of the model with the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:47:30.178437Z",
     "start_time": "2018-12-09T12:47:30.175741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=9, min_samples_split=7,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:47:31.022988Z",
     "start_time": "2018-12-09T12:47:31.019961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252391563162197"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model so it can be used later without doing the expensive gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:47:34.161737Z",
     "start_time": "2018-12-09T12:47:34.154176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/optimal_m_weekday.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(m, Datapath+\"optimal_m_weekday.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model performs with an R2 of about 0.73 which is pretty good.\n",
    "\n",
    "Let's save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:48:12.705181Z",
     "start_time": "2018-12-09T12:48:12.696068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/fitted_m_weekday.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(m, Datapath+\"fitted_m_weekday.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
